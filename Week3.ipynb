{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoyN8lseE5e6M8WkUaBzP2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anusha-tikarya/Hexa_Project/blob/Week3/Week3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1\n",
        "# Set Up Spark\n",
        "!pip install pyspark\n",
        "\n",
        "\n",
        "# Import Necessary Libraries\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, TimestampType\n",
        "from pyspark.sql.functions import col, sum, count\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZt3MPc1E23S",
        "outputId": "76c56903-ab47-4a26-dc4d-6e5005047e14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=632bae2506ce849770ae46ce8820837854d46232c89fb52b7976c960a1ce1693\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"EcommerceRealTime\") \\\n",
        "    .getOrCreate()\n",
        "# Step 3: Create a directory for streaming data\n",
        "streaming_data_path = os.makedirs('/content/streaming_data', exist_ok=True)\n",
        "\n",
        "# Step 4: Define schema for order data\n",
        "schema = StructType([\n",
        "    StructField(\"order_id\", IntegerType(), True),\n",
        "    StructField(\"product_id\", IntegerType(), True),\n",
        "    StructField(\"customer_id\", IntegerType(), True),\n",
        "    StructField(\"quantity\", IntegerType(), True),\n",
        "    StructField(\"order_amount\", FloatType(), True),\n",
        "    StructField(\"order_date\", TimestampType(), True)\n",
        "])\n",
        "\n",
        "# Step 5: Simulate initial streaming data with new values\n",
        "initial_order_data = [\n",
        "    (2001, 1, 3001, 2, 149.99, datetime.now()),  # Order 1\n",
        "    (2002, 2, 3002, 3, 199.99, datetime.now()),  # Order 2\n",
        "    (2003, 3, 3003, 1, 299.99, datetime.now()),  # Order 3\n",
        "    (2004, 4, 3001, 4, 399.99, datetime.now()),  # Order 4\n",
        "    (2005, 5, 3002, 2, 599.99, datetime.now()),  # Order 5\n",
        "]\n",
        "\n",
        "# Create a DataFrame from the list of initial orders\n",
        "df_orders = spark.createDataFrame(initial_order_data, schema)\n",
        "\n",
        "# Show the initial data\n",
        "print(\"Initial Orders:\")\n",
        "df_orders.show()\n",
        "\n",
        "# Step 6: Process Data Using PySpark\n",
        "# Group the data by product_id and calculate the total sales (sum of order_amount) per product\n",
        "product_sales = df_orders.groupBy(\"product_id\").agg(\n",
        "    sum(\"order_amount\").alias(\"total_sales\"),\n",
        "    count(\"order_id\").alias(\"order_count\")\n",
        ")\n",
        "\n",
        "# Show the result\n",
        "print(\"Initial Product Sales:\")\n",
        "product_sales.show()\n",
        "\n",
        "# Step 7: Real-Time Streaming Simulation\n",
        "# Simulating appending new data in real-time with updated values\n",
        "new_order_data = [\n",
        "    (1008, 2, 3004, 2, 249.99, datetime.now()),  # New Order 1\n",
        "    (1009, 4, 3001, 3, 359.95, datetime.now()),  # New Order 2\n",
        "    (1010, 5, 3002, 1, 599.99, datetime.now()),  # New Order 3\n",
        "    (1011, 1, 3003, 4, 149.99, datetime.now()),  # New Order 4\n",
        "    (1012, 3, 3004, 2, 389.50, datetime.now()),  # New Order 5\n",
        "]\n",
        "\n",
        "# Create a new DataFrame for the new batch of orders with the correct timestamp format\n",
        "new_df_orders = spark.createDataFrame(new_order_data, schema)\n",
        "\n",
        "# Append the new data to the original DataFrame\n",
        "df_orders = df_orders.union(new_df_orders)\n",
        "\n",
        "# Perform the same aggregation again with the updated data\n",
        "updated_product_sales = df_orders.groupBy(\"product_id\").agg(\n",
        "    sum(\"order_amount\").alias(\"total_sales\"),\n",
        "    count(\"order_id\").alias(\"order_count\")\n",
        ")\n",
        "\n",
        "# Show the updated result\n",
        "print(\"Updated Product Sales After New Orders:\")\n",
        "updated_product_sales.show()\n",
        "\n",
        "# Step 8: Write the results to a CSV file\n",
        "updated_product_sales.write.csv(\"/content/product_sales.csv\", header=True, mode='overwrite')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwQ7HQoSEpSl",
        "outputId": "5bda7621-fd6d-45fe-a4ee-8b0a487f341d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Orders:\n",
            "+--------+----------+-----------+--------+------------+--------------------+\n",
            "|order_id|product_id|customer_id|quantity|order_amount|          order_date|\n",
            "+--------+----------+-----------+--------+------------+--------------------+\n",
            "|    2001|         1|       3001|       2|      149.99|2024-09-27 10:44:...|\n",
            "|    2002|         2|       3002|       3|      199.99|2024-09-27 10:44:...|\n",
            "|    2003|         3|       3003|       1|      299.99|2024-09-27 10:44:...|\n",
            "|    2004|         4|       3001|       4|      399.99|2024-09-27 10:44:...|\n",
            "|    2005|         5|       3002|       2|      599.99|2024-09-27 10:44:...|\n",
            "+--------+----------+-----------+--------+------------+--------------------+\n",
            "\n",
            "Initial Product Sales:\n",
            "+----------+------------------+-----------+\n",
            "|product_id|       total_sales|order_count|\n",
            "+----------+------------------+-----------+\n",
            "|         1|149.99000549316406|          1|\n",
            "|         2|199.99000549316406|          1|\n",
            "|         3|  299.989990234375|          1|\n",
            "|         5|  599.989990234375|          1|\n",
            "|         4|  399.989990234375|          1|\n",
            "+----------+------------------+-----------+\n",
            "\n",
            "Updated Product Sales After New Orders:\n",
            "+----------+-----------------+-----------+\n",
            "|product_id|      total_sales|order_count|\n",
            "+----------+-----------------+-----------+\n",
            "|         1|299.9800109863281|          2|\n",
            "|         2|449.9800109863281|          2|\n",
            "|         3| 689.489990234375|          2|\n",
            "|         5| 1199.97998046875|          2|\n",
            "|         4|759.9400024414062|          2|\n",
            "+----------+-----------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WPuIEirYE17Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}